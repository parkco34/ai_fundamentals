# Random Search Implementation Guide

## Function Structure
```python
def random_search(model, param_distributions, X_train, y_train, X_val, y_val, n_iter=10):
    """
    Your docstring should explain:
    - Purpose of the function
    - Parameters and their types
    - Return value
    - Example usage
    """
     ? # Your implementation here
```

## Components You'll Need

### 1. Parameter Generation
- Create a function to generate random values for each hyperparameter
- Consider different types of parameters:
  - Integer values (e.g., max_depth)
  - Float values (e.g., learning_rate)
  - Categorical values (e.g., criterion)

### 2. Parameter Sampling Logic
You'll need to handle:
1. Integer ranges
   - Example: max_depth between 1 and 20
   - Think: How to generate random integers in a range?

2. Float ranges
   - Example: min_samples_split between 0.1 and 1.0
   - Think: How to generate random floats in a range?

3. Categorical choices
   - Example: criterion from ['gini', 'entropy']
   - Think: How to randomly select from a list?

### 3. Model Evaluation
For each parameter combination:
1. Create a new model instance
2. Train the model
3. Evaluate performance
4. Store results

### 4. Results Tracking
Create data structures to store:
1. All parameter combinations tried
2. Performance scores for each combination
3. Best parameters found
4. Best score achieved

## Implementation Steps

1. Parameter Generation
   ```python
   # You'll need to implement this
   def generate_random_params(param_distributions):
       """
       Input: Dictionary of parameter distributions
       Output: Dictionary of sampled parameters
       
       Think about:
       1. How to handle different parameter types?
       2. How to ensure values are within valid ranges?
       3. How to handle dependencies between parameters?
       """
       ?
   ```

2. Performance Evaluation
   ```python
   # You'll need to implement this
   def evaluate_params(model, params, X_train, y_train, X_val, y_val):
       """
       Input: Model, parameters, and data
       Output: Performance score
       
       Think about:
       1. How to fit the model with new parameters?
       2. What metric to use for evaluation?
       3. How to handle potential errors?
       """
       ?
   ```

## Error Handling Considerations

Think about how to handle:
1. Invalid parameter combinations
2. Training failures
3. Evaluation errors
4. Edge cases in parameter ranges

## Testing Strategy

Plan to test:
1. Parameter generation
   - Are values in valid ranges?
   - Are all parameters being sampled?

2. Model evaluation
   - Does it handle different metrics?
   - Does it properly track best results?

3. Edge cases
   - Empty parameter distributions
   - Single parameter value
   - Invalid parameter combinations

## Example Parameter Distributions

```python
param_distributions = {
    'max_depth': {'type': 'int', 'range': (1, 20)},
    'min_samples_split': {'type': 'int', 'range': (2, 10)},
    'min_samples_leaf': {'type': 'int', 'range': (1, 5)},
    'criterion': {'type': 'categorical', 'values': ['gini', 'entropy']}
}
```

## Implementation Tips

1. Start Simple
   - Begin with handling one parameter type
   - Add complexity gradually
   - Test each addition

2. Validation Steps
   - Verify parameter ranges
   - Check parameter combinations
   - Validate model creation

3. Performance Tracking
   - Use appropriate data structures
   - Consider memory efficiency
   - Track iteration progress

## Common Pitfalls to Avoid

1. Parameter Validation
   - Not checking parameter types
   - Ignoring valid ranges
   - Missing dependent parameters

2. Performance Evaluation
   - Not handling model errors
   - Incorrect metric calculation
   - Memory leaks

3. Result Storage
   - Overwriting best results
   - Not storing all trials
   - Insufficient error logging

## Optional Enhancements

Once basic implementation works, consider:
1. Progress tracking
2. Early stopping
3. Parameter importance analysis
4. Parallel execution
5. Result visualization

## Usage Example Template

```python
# Example of how your implementation should be used
param_distributions = {
    'max_depth': {'type': 'int', 'range': (1, 20)},
    'criterion': {'type': 'categorical', 'values': ['gini', 'entropy']}
}

# Your implementation should support this usage pattern
best_params, best_score = random_search(
    model=DecisionTree(),
    param_distributions=param_distributions,
    X_train=X_train,
    y_train=y_train,
    X_val=X_val,
    y_val=y_val,
    n_iter=10
)
```
